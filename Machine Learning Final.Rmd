---
title: "Machine Learning Final"
output: html_document
---
In the Below Data I am Downloading the Traing and Test data for the assignment. We then load the packages that will be used to prdict the Classe. Finally We create our training data and our Test data that we split 60/40.


```{r}
download.pml <- function() {
  download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "pml-training.csv")
  download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "pml-testing.csv")
}

library(caret)
library(randomForest)

trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
set.seed(55)

inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]; myTesting <- training[-inTrain, ]
```

Cleaning the data and removing colums that are beleived to not be required for predicting. We use Near zero varence and 

```{r}
myDataNZV <- nearZeroVar(myTraining, saveMetrics=FALSE) # find the colums that have Near Zero varence
myTraining <- myTraining[,-myDataNZV] # remove those colums from the data set so that they do not interfer with the predition


myTraining <- myTraining[c(-1)]
trainingV3 <- myTraining #creating another subset to iterate in loop
for(i in 1:length(myTraining)) { 
  if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .51 ) { #if n?? NAs > 51% of total observations
    for(j in 1:length(trainingV3)) {
      if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) ==1)  { #if the columns are the same:
        trainingV3 <- trainingV3[ , -j] 
      }   
    } 
  }
}
myTraining <- trainingV3
rm(trainingV3)

clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -58])
myTesting <- myTesting[clean1]
testing <- testing[clean2]

for (i in 1:length(testing) ) {
  for(j in 1:length(myTraining)) {
    if( length( grep(names(myTraining[i]), names(testing)[j]) ) ==1)  {
      class(testing[j]) <- class(myTraining[i])
    }      
  }      
}

testing <- rbind(myTraining[2, -58] , testing) #note row 2 does not mean anything, this will be removed right.. now:
testing <- testing[-1,]
```

Creating the model and determing the sample error.

```{r}
modFit <- randomForest(classe ~. , data=myTraining)
predictions <- predict(modFit, myTesting, type = "class")
confusionMatrix(predictions, myTesting$classe)
```
We find that there is a 99% accuracy so the predicion model should be sufficent for testing. I would expect that the data will only generate an incorrect projection 1% of the time.

Writing the text files for submission

```{r} 
predictions <- predict(modFit, testing, type = "class")
predictions = rep("A", 20)

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictions)
```
